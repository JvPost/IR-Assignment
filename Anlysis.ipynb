{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marco/anaconda3/envs/IR/lib/python3.9/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "from pyserini.index import IndexReader \n",
    "from pyserini.search import SimpleSearcher\n",
    "import gensim\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "import gensim.downloader as api\n",
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "import codecs\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm\n",
    "from utils import *\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "config = json.loads(open(\"config.json\", \"r\").read())\n",
    "index_path = config[\"index_path\"]\n",
    "topics_path = config[\"topics_path\"]\n",
    "qrels_path = config[\"qrels_path\"]\n",
    "index_path\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wiki_50 = api.load('glove-wiki-gigaword-50')\n",
    "wiki_300 = api.load('glove-wiki-gigaword-300')\n",
    "# google = api.load('word2vec-google-news-300')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hubble space telescope nasa spacecraft observatory astronomers infrared shuttle astronauts nasa observatories orbiting'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expand_query('hubble space telescope', wiki_300, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:05<00:00, 45.20it/s]\n",
      "100%|██████████| 250/250 [00:42<00:00,  5.89it/s]\n"
     ]
    }
   ],
   "source": [
    "topics = get_topics(topics_path)\n",
    "#k = nro. results per topic\n",
    "#n = nro. extra words\n",
    "k = 400\n",
    "n = 10\n",
    "\n",
    "def make_results(model, n:int, dynamic = False, k:int = 25):\n",
    "    results = \"\"\n",
    "    for i in tqdm(topics):\n",
    "        ranking = \"\"\n",
    "        if n > 0:\n",
    "            if dynamic:\n",
    "                n = len(topics[i].split())\n",
    "            expanded_topic = expand_query(topics[i], model, n)\n",
    "            hits = Searcher.search(expanded_topic, k=k)\n",
    "        else:\n",
    "            hits = Searcher.search(topics[i], k=k)\n",
    "        for r, h in enumerate(hits):\n",
    "            ranking += f\"{i} 0 {h.docid} {r+1} {h.score} RUN1\\n\"\n",
    "        results += ranking\n",
    "        \n",
    "    filename = \"\"\n",
    "    if not dynamic:\n",
    "        filename = f'results/results_{n}_{k}.txt'\n",
    "    else:\n",
    "        filename = f'results/results_x_{k}.txt'\n",
    "        \n",
    "    f = open(filename, 'w')\n",
    "    f.write(results)\n",
    "    f.close()\n",
    "    \n",
    "def create_test_data(model, n:int, k:int = 25):\n",
    "    make_results(model, 0, True, k) # no expanded query\n",
    "    make_results(model, n, True, k) # expanded query\n",
    "    \n",
    "\n",
    "create_test_data(wiki_300, n, k=k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 400 0.588354224730254\n"
     ]
    }
   ],
   "source": [
    "metric = 0\n",
    "\n",
    "labels_gen = query_labels_from_file(qrels_path, f'results/results_x_{k}.txt')\n",
    "r = 0\n",
    "for labels in labels_gen:\n",
    "    metric+=NDCG(labels, k)\n",
    "    r+=1\n",
    "     \n",
    "print(f\"{n} {k} {metric/r}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 400 0.34524561346018595\n"
     ]
    }
   ],
   "source": [
    "metric_0 = 0\n",
    "\n",
    "labels_gen = query_labels_from_file(qrels_path, f'results/results_0_{k}.txt')\n",
    "r = 0\n",
    "for labels in labels_gen:\n",
    "    metric_0+=NDCG(labels, 25)\n",
    "    r+=1\n",
    "    \n",
    "print(f\"0 {k} {metric_0/r}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
