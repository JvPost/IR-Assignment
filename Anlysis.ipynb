{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marco/anaconda3/envs/IR/lib/python3.9/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "from pyserini.index import IndexReader \n",
    "from pyserini.search import SimpleSearcher\n",
    "import gensim\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "import gensim.downloader as api\n",
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "import codecs\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm\n",
    "from utils import *\n",
    "\n",
    "config = json.loads(open(\"config.json\", \"r\").read())\n",
    "index_path = config[\"index_path\"]\n",
    "topics_path = config[\"topics_path\"]\n",
    "qrels_path = config[\"qrels_path\"]\n",
    "index_path\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection length = 174540872\n"
     ]
    }
   ],
   "source": [
    "index_reader = IndexReader(index_path)\n",
    "searcher = SimpleSearcher(index_path)\n",
    "sample_topic = \"hubble space telescope\"\n",
    "topics = [sample_topic]\n",
    "\n",
    "global len_C\n",
    "len_C = index_reader.stats()['total_terms']\n",
    "print(\"Collection length =\", len_C)\n",
    "\n",
    "\n",
    "searcher.set_bm25(0.9, 0.4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_50 = api.load('glove-wiki-gigaword-50')\n",
    "wiki_300 = api.load('glove-wiki-gigaword-300')\n",
    "# google = api.load('word2vec-google-news-300')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hubble space telescope telescopes hubble telescope'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expand_query(sample_topic, wiki_300, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:02<00:00, 83.67it/s]\n"
     ]
    }
   ],
   "source": [
    "topics = get_topics(topics_path)\n",
    "#k = nro. results per topic\n",
    "#n = nro. extra words per topic\n",
    "k = 25\n",
    "n = 0\n",
    "\n",
    "def make_results(model, n:int, k:int = 25):\n",
    "    results = \"\"\n",
    "    for i in tqdm(topics):\n",
    "        ranking = \"\"\n",
    "        if k > 0:\n",
    "            expanded_topic = expand_query(topics[i], model, n)\n",
    "            hits = searcher.search(expanded_topic, k=k)\n",
    "        else:\n",
    "            hits = searcher.search(topics[i])\n",
    "        for r, h in enumerate(hits):\n",
    "            ranking += f\"{i} 0 {h.docid} {r+1} {h.score} RUN1\\n\"\n",
    "        results += ranking\n",
    "        \n",
    "    f = open(f'results_{n}_{k}.txt', 'w')\n",
    "    f.write(results)\n",
    "    f.close()\n",
    "    \n",
    "make_results(wiki_300, n, k=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6142347126883415"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndcg25 = 0\n",
    "\n",
    "labels_gen = query_labels_from_file(qrels_path, 'results_3_25.txt')\n",
    "r = 0\n",
    "for labels in labels_gen:\n",
    "    ndcg25+=NDCG(labels, 25)\n",
    "    r+=1\n",
    "     \n",
    "ndcg25/r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7017154670166613"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndcg25 = 0\n",
    "\n",
    "labels_gen = query_labels_from_file(qrels_path, 'results_0_25.txt')\n",
    "r = 0\n",
    "for labels in labels_gen:\n",
    "    ndcg25+=NDCG(labels, 25)\n",
    "    r+=1\n",
    "    \n",
    "ndcg25/r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
